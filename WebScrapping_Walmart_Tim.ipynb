{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paayala-rubio/Coffee-in-Canada/blob/main/WebScrapping_Walmart_Tim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyzyknCUr-Zy",
        "outputId": "fd9e5113-56ab-443b-96a9-b5cae5dfe4d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4 pandas\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "\n",
        "# Add this inside the loop\n",
        "time.sleep(random.uniform(1, 3))  # 1–3 second delay"
      ],
      "metadata": {
        "id": "ossM7hGZAu7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scraping of Multiple Pages\n",
        "reviews_data = []\n",
        "\n",
        "for page in tqdm(range(1, 218), desc=\"Scraping pages\"):\n",
        "    url = f'https://www.walmart.ca/en/reviews/product/6000199413869?entryPoint=viewAllReviewsBottom&page={page}.html'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    reviews = soup.find_all('div', class_='overflow-visible b--none mt4-l ma0 dark-gray')\n",
        "\n",
        "    for review in reviews:\n",
        "        date = review.find('div', class_='f7 gray flex flex-auto flex-none-l tr tl-l justify-end justify-start-l')\n",
        "        user = review.find('span', class_='f7 b mv0')\n",
        "        details = review.find('span', class_='tl-m db-m')\n",
        "        stars = review.find('span', class_='w_q67L')\n",
        "        title = review.find('span', class_='w_vi_D')\n",
        "        user_type = review.find('span', class_='b f7 dark-gray')\n",
        "\n",
        "        reviews_data.append({\n",
        "            'Review_Date': date.text.strip() if date else None,\n",
        "            'User_Name': user.text.strip() if user else None,\n",
        "            'User_Type': user_type.text.strip() if user_type else None,\n",
        "            'Stars' : stars.text.strip() if stars else None,\n",
        "            'Title' : title.text.strip() if title else None,\n",
        "            'Details': details.text.strip() if details else None\n",
        "        })\n",
        "\n",
        "\n",
        "df_all = pd.DataFrame(reviews_data)\n",
        "print(df_all.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6TDXmz7Ai_e",
        "outputId": "22282c82-55e8-4897-80f4-53ebf1228777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scraping pages: 100%|██████████| 217/217 [06:36<00:00,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Review_Date           User_Name          User_Type  \\\n",
            "0  Jan 15, 2025       Rightsidefred  Verified Purchase   \n",
            "1  Jan 26, 2025     Flameschickie68  Verified Purchase   \n",
            "2  Jan 26, 2025  Walter Waltermelom  Verified Purchase   \n",
            "3  Apr 29, 2025    Walmart customer  Verified Purchase   \n",
            "4   Nov 8, 2024          ToddfromBC  Verified Purchase   \n",
            "\n",
            "                     Stars                                   Title  \\\n",
            "0  5 out of 5 stars review                             Good Coffee   \n",
            "1  5 out of 5 stars review                                   Yummy   \n",
            "2  5 out of 5 stars review                                     MMM   \n",
            "3  5 out of 5 stars review                     Addicted to timmies   \n",
            "4  5 out of 5 stars review  Timmy's what more do you need to say ?   \n",
            "\n",
            "                                             Details  \n",
            "0  Eventhough It doesn't taste exactly as Tim Hor...  \n",
            "1  Perfect..especially with the Tim Hortons doubl...  \n",
            "2  Great taste for and very great taste for the p...  \n",
            "3  My husband's favourite  brand  for over  30 ye...  \n",
            "4  Can't beat Timmy's, always the same medium roa...  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save dataframe to CSV\n",
        "df_all.to_csv('reviews_data_Tim.csv', index=False)"
      ],
      "metadata": {
        "id": "RxVKUA_vsuUz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}